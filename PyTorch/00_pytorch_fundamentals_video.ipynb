{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec22efd-8879-4889-82cd-2fd35d5583cc",
   "metadata": {},
   "source": [
    "00 Pytorch Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "684cf875-6bd7-4aca-a66f-122f13cee84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6673ea-5a0f-45ee-aa47-200822f333eb",
   "metadata": {},
   "source": [
    "Introduction to Tensors\n",
    "\n",
    "    Creating tensors\n",
    "    \n",
    "        PyTorch tensors are created using 'torch.tensor()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd868b19-09e3-4ec3-8722-768aa801122e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df2acbb9-a349-4263-a899-834b414e2fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5409fec4-ee67-4b8b-9f19-c2affa310cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as a Python \n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f451831-f7ee-4af8-ae12-d587c4e49a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c082043d-8432-46a0-abd3-beb9b7efa6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b4e980b-46d5-44f2-bcb8-8f23d52a1a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c52ef187-5265-4985-af43-0f1c1e9db61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "MATRIX = torch.tensor([[7, 8],\n",
    "                       [9,10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "400ac29c-ada8-490e-966a-a2bd1be46926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd909913-3933-4dab-ab3e-4889f175b629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4241446c-1db5-48c6-a080-0351989e11e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e957f2a-e540-4709-a99e-7a1ae0ee4e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b1d63af-9314-4572-945a-ac8d87aee874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                       [4,5,6],\n",
    "                       [7,8,9]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4749c52-c939-43b3-9d50-ff8da9a8545f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "937f0979-f4af-4fd9-921a-cec5b35b765b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04377a3b-abff-450a-b874-e85c10b96913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34c55a8a-0300-42b0-8215-a54452ceeca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a247f34-b4f7-4315-bb15-6af1d8533288",
   "metadata": {},
   "source": [
    "    Random Tensors\n",
    "\n",
    "        Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data\n",
    "\n",
    "        Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ea8aeec-a308-4a2b-bd8e-9d7fef1234fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2044, 0.5298, 0.4618, 0.3288],\n",
       "        [0.2106, 0.0619, 0.5976, 0.9616],\n",
       "        [0.9848, 0.0822, 0.4709, 0.0159]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3,4)\n",
    "random_tensor = torch.rand(3,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e8af330-629a-4627-ab1d-4058ec1bc304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99590add-a373-42fd-9a93-7d8fa1ce5204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b14dcc5-c34a-4f00-8deb-052497a9c49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0702, 0.9335, 0.2951, 0.3924, 0.1715, 0.2638, 0.5963, 0.8093, 0.1537,\n",
       "         0.0156],\n",
       "        [0.2333, 0.1939, 0.6473, 0.5344, 0.3584, 0.5622, 0.4344, 0.9663, 0.8716,\n",
       "         0.2215],\n",
       "        [0.1734, 0.5149, 0.5584, 0.0168, 0.8589, 0.6908, 0.9942, 0.8060, 0.2089,\n",
       "         0.6393],\n",
       "        [0.2398, 0.5422, 0.4491, 0.6084, 0.0309, 0.5193, 0.6801, 0.4147, 0.1762,\n",
       "         0.5417],\n",
       "        [0.3019, 0.7161, 0.8272, 0.2770, 0.6640, 0.5520, 0.5621, 0.0062, 0.7547,\n",
       "         0.0208],\n",
       "        [0.9021, 0.8397, 0.6692, 0.1398, 0.7766, 0.3226, 0.6844, 0.3678, 0.0731,\n",
       "         0.1342],\n",
       "        [0.3843, 0.7392, 0.1547, 0.4750, 0.2455, 0.8664, 0.5348, 0.2911, 0.4875,\n",
       "         0.9753],\n",
       "        [0.4956, 0.5663, 0.5652, 0.0875, 0.9762, 0.1820, 0.9011, 0.4690, 0.7771,\n",
       "         0.4660],\n",
       "        [0.7683, 0.3125, 0.8008, 0.3030, 0.5046, 0.9801, 0.7702, 0.3158, 0.1748,\n",
       "         0.1724],\n",
       "        [0.1792, 0.6008, 0.7742, 0.2666, 0.9425, 0.6191, 0.7804, 0.1731, 0.8545,\n",
       "         0.6495]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(10,10)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52284094-4750-4938-95ec-6c89a9dca31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad68ba1c-a565-44a7-bcfa-06f74708a724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7d30eda-12e1-46bf-8146-e6effd8959bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8978, 0.6794, 0.9432, 0.7936],\n",
       "         [0.8856, 0.5356, 0.0083, 0.6406],\n",
       "         [0.9377, 0.2226, 0.2612, 0.8727],\n",
       "         [0.6113, 0.3169, 0.5221, 0.9043]],\n",
       "\n",
       "        [[0.0091, 0.3252, 0.7626, 0.7767],\n",
       "         [0.9656, 0.4645, 0.3570, 0.1906],\n",
       "         [0.0745, 0.6886, 0.5069, 0.0128],\n",
       "         [0.8697, 0.4614, 0.8684, 0.1547]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(2, 4, 4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59a1e3bd-4d82-4e3e-b42c-de94c1f2310f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec7bb18b-8467-4349-afba-ea05ecd9e199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78fc81e7-c789-431f-91f3-5c11f6f5d956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(3,224,224)) # colour channels (R, G, B), height, width\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f7139c0-ffe3-4588-b9a8-756e2e430049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1761, 0.5826, 0.6750,  ..., 0.6129, 0.3553, 0.5254],\n",
      "         [0.2607, 0.2387, 0.3879,  ..., 0.4969, 0.3431, 0.3720],\n",
      "         [0.9315, 0.5511, 0.5428,  ..., 0.8905, 0.4803, 0.1434],\n",
      "         ...,\n",
      "         [0.9821, 0.4614, 0.3396,  ..., 0.8083, 0.2782, 0.8429],\n",
      "         [0.6229, 0.4920, 0.5134,  ..., 0.5006, 0.7077, 0.7086],\n",
      "         [0.1625, 0.6715, 0.8144,  ..., 0.4337, 0.0775, 0.7361]],\n",
      "\n",
      "        [[0.6304, 0.7180, 0.1804,  ..., 0.0807, 0.0921, 0.2429],\n",
      "         [0.0347, 0.6022, 0.4846,  ..., 0.7700, 0.8434, 0.5208],\n",
      "         [0.4436, 0.3397, 0.4133,  ..., 0.0726, 0.5593, 0.0197],\n",
      "         ...,\n",
      "         [0.1631, 0.8896, 0.7386,  ..., 0.3835, 0.2664, 0.3034],\n",
      "         [0.9286, 0.3029, 0.1789,  ..., 0.7495, 0.0976, 0.9284],\n",
      "         [0.9651, 0.6033, 0.7516,  ..., 0.5986, 0.3985, 0.2281]],\n",
      "\n",
      "        [[0.3534, 0.3765, 0.2551,  ..., 0.6241, 0.3142, 0.4140],\n",
      "         [0.9642, 0.9249, 0.4527,  ..., 0.3905, 0.2526, 0.3783],\n",
      "         [0.4115, 0.1920, 0.2541,  ..., 0.6772, 0.3130, 0.5077],\n",
      "         ...,\n",
      "         [0.7095, 0.3915, 0.2034,  ..., 0.7514, 0.0595, 0.2855],\n",
      "         [0.1918, 0.8412, 0.8553,  ..., 0.3076, 0.0319, 0.5052],\n",
      "         [0.4565, 0.0714, 0.7890,  ..., 0.3051, 0.0015, 0.1529]]])\n"
     ]
    }
   ],
   "source": [
    "print(random_image_size_tensor) # Do not need this print statement in Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8a9df4-c173-4d51-aee0-d194585663e4",
   "metadata": {},
   "source": [
    "    Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e670c7d9-1ef5-4c7e-b478-1910c7655820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa08c876-7244-486a-be09-da3b7c3862a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(3,4) # To reset my playing around with code above\n",
    "zeros * random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a4411e3-69aa-4c8c-9e6e-18804a673d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3,4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29754011-51a5-4192-9db6-1ad41904e4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b92137d-b994-4372-af82-9f9adeec2e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd379f66-4f99-452e-ae41-5ef7af663bcd",
   "metadata": {},
   "source": [
    "    Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a224826d-59c4-4920-b59e-d5a5ee4e2e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.arange()\n",
    "torch.arange(0,10)\n",
    "\n",
    "# torch.range() no longer works with my version of PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68cb9670-f677-42c8-b616-54c2099fac4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  77, 154, 231, 308, 385, 462, 539, 616, 693, 770, 847, 924])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "something = torch.arange(start=0, end=1000, step=77)\n",
    "something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36fd478b-6b11-44a1-8e30-51667876591e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "something.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6ad93cd-b5b9-42ee-9d75-423b8f7255fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "something.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "858621c3-b250-47af-a72d-dc64a2fc06fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a tensors like\n",
    "ten_zeros = torch.zeros_like(input=something)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a1260-6b02-4ac4-8754-cb86a6f4d49e",
   "metadata": {},
   "source": [
    "    Tensor datatypes\n",
    "\n",
    "        Tensor datatypes is one the 3 big errors you'll run into with PyTorch and deep learning\n",
    "            - Tensors not right datatype\n",
    "            - Tensors not right shape\n",
    "            - Tensors not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2aae0525-1e5d-40d2-a187-c2725c4cec9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], \n",
    "                               dtype=None, # what datatype is the tensor (e.g. float32 or float16)\n",
    "                               device=None, # what device is you tensor on\n",
    "                                   # defualt is \"cpu\"\n",
    "                                   # can change it to \"cuda\"\n",
    "                               requires_grad=False) # whether or not to track gradients with this tensor operations\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97c070e0-659b-4c73-8a80-c57b35cc2572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f25cdb66-9f5c-445f-8b23-70a9930ff306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.half)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e869216-1e24-4a4d-803b-92aa52621d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor = float_16_tensor * float_32_tensor\n",
    "test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43790a51-8076-44fb-a5f6-34f6e751095b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "211bdec3-b530-4af9-853c-1247cebde5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3,6,9], dtype=torch.int32)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a106a151-086b-4711-a1e9-458b2eee4689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor = float_32_tensor * int_32_tensor\n",
    "test_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d290bca-3bc4-4ac4-ba79-091c063d9316",
   "metadata": {},
   "source": [
    "    Getting information from tensors (Tensor attributes)\n",
    "\n",
    "        To get datatype from a tensor, use 'tensor.dtype'\n",
    "        To get shape from a tensor, use 'tensor.shape'\n",
    "        To get device from a tensor, use 'tensor.device'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f40a1a12-4a45-4a0a-8182-1fd8c9b2f74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4805, 0.7664, 0.1543, 0.1762],\n",
       "        [0.8518, 0.9389, 0.8364, 0.7943],\n",
       "        [0.0217, 0.4235, 0.5792, 0.1534]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9cf3f421-8e6d-4b7d-8773-4b1132e42a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4805, 0.7664, 0.1543, 0.1762],\n",
      "        [0.8518, 0.9389, 0.8364, 0.7943],\n",
      "        [0.0217, 0.4235, 0.5792, 0.1534]])\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device tensor is on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Find out details about some tensor\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device tensor is on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f45db9a9-09c8-4554-a44b-525f0860f598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]), torch.Size([3, 4]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.size(), some_tensor.shape  # not some_tensor.size... it is not an attribute, but a function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e77c8b-e417-4853-8168-b2cd172e37df",
   "metadata": {},
   "source": [
    "    Manipulating Tensors (Tensor operations)\n",
    "\n",
    "        Tensor operations include:\n",
    "            - addition\n",
    "            - subtractions\n",
    "            - multiplication (element-wise)\n",
    "            - division\n",
    "            - matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6fc92f4-0b39-4cca-ae8b-543be239d05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1025, 1026, 1027])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25607e70-8d14-4517-8b71-41adc1cd1efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b4f04ce-edb6-4088-a743-1b33e9447ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75619871-2605-4feb-a965-c93a131cad8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor * 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4848bde1-af8b-482c-9769-1b60b788f3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "494724cb-afec-4894-98a5-27eea2983636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e641684e-d361-42da-9c33-e9f54dc0aef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(tensor,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50d5848f-c94f-40a8-8428-a56b70d31696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9fc4eafa-f33a-4d14-bfda-7a77b351edd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "889d0951-d6dc-458a-8f36-4c8ac97be950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sub(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6412f6fc-def7-49a1-b8af-a9ff84ad1e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 1.0000, 1.5000])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.div(tensor, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a387ad-8945-4a7b-86cf-aff49c3425cf",
   "metadata": {},
   "source": [
    "    Matrix Multiplication\n",
    "\n",
    "        Two main ways of performing multiplication in neural netwroks and deep learning:\n",
    "            - element-wise multiplication\n",
    "            - matrix multiplication\n",
    "\n",
    "        There are two main rules that performing matrix multiplication needs to satisfy:\n",
    "            - the inner dimensions must match\n",
    "                - (3,2) @ (3,2) will not work\n",
    "                - (2,3) @ (3,2) will work\n",
    "                - (3,2) @ (2,3) will work\n",
    "            - resulting matrix has the shape of the outer dimensions\n",
    "                - (2,3) @ (3,2) will yield a (2,2)\n",
    "                - (3,2) @ (2,3) will yield a (3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a235bf6b-a4dc-47b6-bd2d-c122784e6f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.7807, 0.5811],\n",
       "        [0.3126, 1.4749, 0.9558],\n",
       "        [0.2268, 0.6327, 0.3033]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.rand(3,2), torch.rand(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "adf94b4a-6d91-4466-9303-3098a19b0b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2934, 0.6418],\n",
       "        [0.6299, 1.1575]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.rand(2,3), torch.rand(3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fa91c54e-f29b-4d17-9f4d-2b025684b5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication\n",
    "print(tensor, \"*\", tensor)\n",
    "print(f\"Equals: {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7308f71a-88c6-4390-b61f-9dfbcca3721f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix Multiplication\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "922a7368-52a5-4cf3-bfc6-42653de3b469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication by hand\n",
    "1*1 + 2*2 + 3*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b520507d-7570-4169-86d8-385b7f27aa8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d225f094-17be-4c41-ba20-211a2bcf1ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b488fdb2-a550-4f74-8f3c-7d041d51b109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd9245-a7c6-4c72-b4a4-64b976f05d0f",
   "metadata": {},
   "source": [
    "    One of the most common errors in deep learning: shape errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8aea84cf-fa56-469a-84d5-fe822434a940",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m tensor_A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      3\u001b[0m                          [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m],\n\u001b[0;32m      4\u001b[0m                          [\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m]])\n\u001b[0;32m      6\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      7\u001b[0m                          [\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m11\u001b[39m],\n\u001b[0;32m      8\u001b[0m                          [\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m12\u001b[39m]])\n\u001b[1;32m---> 10\u001b[0m torch\u001b[38;5;241m.\u001b[39mmm(tensor_A, tensor_B)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes for matrix multiplication\n",
    "tensor_A = torch.tensor([[1,2],\n",
    "                         [3,4],\n",
    "                         [5,6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7,10],\n",
    "                         [8,11],\n",
    "                         [9,12]])\n",
    "\n",
    "torch.mm(tensor_A, tensor_B) # torch.mm() is the same as torch.matmul()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9084574e-5cd4-455d-a5b1-52257860c967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A.shape, tensor_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998ce69d-253e-4bc1-9d3a-a4e62b926da5",
   "metadata": {},
   "source": [
    "        To fix our tensor shape issues, we can manipulate the shape of one of our tensors using a transpose \n",
    "\n",
    "        A transpose seithces the axes or dimensions of a given tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a2dad718-535b-44d9-a88c-fb6b07fe34d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7, 10],\n",
       "        [ 8, 11],\n",
       "        [ 9, 12]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "be2c6afd-b5b4-41bd-a08f-bc0d7d40e07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  8,  9],\n",
       "         [10, 11, 12]]),\n",
       " torch.Size([3, 2]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T, tensor_B.shape # tensor_B.T does not change tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7af1d5e2-7f81-447a-8a50-90489b72abce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6bdf0b42-6e87-4fc6-be94-3f6b5c6eab30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "New Shapes: tensor_A = torch.Size([3, 2]) (same shape as above), tensor_B.T = torch.Size([2, 3])\n",
      "Multiplying: torch.Size([3, 2]) @ torch.Size([3, 2]) <- inner dimensions must match\n",
      "Output:\n",
      "\n",
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# The matrix multiplication operation works when tensor_B is transposed\n",
    "print(f\"Original Shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\")\n",
    "print(f\"New Shapes: tensor_A = {tensor_A.shape} (same shape as above), tensor_B.T = {tensor_B.T.shape}\")\n",
    "print(f\"Multiplying: {tensor_A.shape} @ {tensor_B.shape} <- inner dimensions must match\")\n",
    "\n",
    "print(\"Output:\\n\")\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output)\n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aa905b-d4f9-46f3-b078-a7fd030f4c26",
   "metadata": {},
   "source": [
    "    Finding the min, max, mean, sum, etcetera (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9843aa8a-7968-45fd-b890-027ef77ec211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8cc6ee90-347f-4486-8da8-05ec59236965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the min\n",
    "torch.min(x), x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "03a952e3-ae1d-4d1b-be81-f6db8d6e9837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the max\n",
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fb82e3bd-67b0-4bc9-b40b-8ac55bd76466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the mean\n",
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean() # torch.mean() function requires a tensor of float32 datatype to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "76f9b8a7-f850-421d-9f07-5bedc6182a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the sum\n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d760394a-a91d-452d-871b-e09381792d6b",
   "metadata": {},
   "source": [
    "    Finding the positional min and mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9586fd1e-7b12-40b4-95e5-b8edf7697c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tensor that has the minimum value with argmin() -> returns index position of target tensor where min occurs\n",
    "x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b16acf3b-58d8-4bc0-b3ab-d382a6f4c156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tensor that has the max value with argmax()\n",
    "x.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "830cb937-126d-4e8f-94dd-6a6bfad7820f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "tensor(90)\n"
     ]
    }
   ],
   "source": [
    "print(x[0])\n",
    "print(x[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04a8922-92b7-4f3d-a7af-c6fbced84d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
