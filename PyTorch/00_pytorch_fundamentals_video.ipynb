{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec22efd-8879-4889-82cd-2fd35d5583cc",
   "metadata": {},
   "source": [
    "00 Pytorch Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "684cf875-6bd7-4aca-a66f-122f13cee84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6673ea-5a0f-45ee-aa47-200822f333eb",
   "metadata": {},
   "source": [
    "Introduction to Tensors\n",
    "\n",
    "    Creating tensors\n",
    "    \n",
    "        PyTorch tensors are created using 'torch.tensor()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd868b19-09e3-4ec3-8722-768aa801122e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df2acbb9-a349-4263-a899-834b414e2fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5409fec4-ee67-4b8b-9f19-c2affa310cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as a Python \n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f451831-f7ee-4af8-ae12-d587c4e49a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c082043d-8432-46a0-abd3-beb9b7efa6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b4e980b-46d5-44f2-bcb8-8f23d52a1a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c52ef187-5265-4985-af43-0f1c1e9db61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "MATRIX = torch.tensor([[7, 8],\n",
    "                       [9,10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "400ac29c-ada8-490e-966a-a2bd1be46926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd909913-3933-4dab-ab3e-4889f175b629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4241446c-1db5-48c6-a080-0351989e11e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e957f2a-e540-4709-a99e-7a1ae0ee4e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b1d63af-9314-4572-945a-ac8d87aee874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                       [4,5,6],\n",
    "                       [7,8,9]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4749c52-c939-43b3-9d50-ff8da9a8545f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "937f0979-f4af-4fd9-921a-cec5b35b765b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04377a3b-abff-450a-b874-e85c10b96913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34c55a8a-0300-42b0-8215-a54452ceeca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a247f34-b4f7-4315-bb15-6af1d8533288",
   "metadata": {},
   "source": [
    "    Random Tensors\n",
    "\n",
    "        Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data\n",
    "\n",
    "        Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ea8aeec-a308-4a2b-bd8e-9d7fef1234fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4587, 0.1000, 0.9918, 0.7308],\n",
       "        [0.2756, 0.1967, 0.6976, 0.7666],\n",
       "        [0.7203, 0.0818, 0.2175, 0.2776]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3,4)\n",
    "random_tensor = torch.rand(3,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e8af330-629a-4627-ab1d-4058ec1bc304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99590add-a373-42fd-9a93-7d8fa1ce5204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b14dcc5-c34a-4f00-8deb-052497a9c49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9209, 0.5626, 0.6200, 0.8958, 0.8294, 0.7332, 0.4533, 0.7560, 0.8724,\n",
       "         0.6790],\n",
       "        [0.4948, 0.9946, 0.1851, 0.1363, 0.9588, 0.0667, 0.1740, 0.1851, 0.1396,\n",
       "         0.8903],\n",
       "        [0.5217, 0.9692, 0.6408, 0.2853, 0.2742, 0.7347, 0.5279, 0.5871, 0.1317,\n",
       "         0.3417],\n",
       "        [0.7542, 0.4048, 0.1088, 0.8171, 0.8593, 0.4267, 0.4757, 0.4779, 0.2283,\n",
       "         0.2915],\n",
       "        [0.5423, 0.3699, 0.7821, 0.4779, 0.9180, 0.9282, 0.2265, 0.0018, 0.3619,\n",
       "         0.8841],\n",
       "        [0.4456, 0.0701, 0.9653, 0.5628, 0.3690, 0.5388, 0.9132, 0.6608, 0.4180,\n",
       "         0.9140],\n",
       "        [0.3255, 0.7278, 0.2856, 0.9997, 0.3797, 0.3209, 0.3484, 0.5236, 0.2965,\n",
       "         0.2189],\n",
       "        [0.9360, 0.3619, 0.3025, 0.7283, 0.2601, 0.5552, 0.9154, 0.6800, 0.8684,\n",
       "         0.6833],\n",
       "        [0.7167, 0.2589, 0.9829, 0.1791, 0.3885, 0.9008, 0.3474, 0.6461, 0.0280,\n",
       "         0.3874],\n",
       "        [0.7926, 0.8635, 0.7523, 0.0734, 0.5302, 0.6938, 0.7401, 0.3794, 0.8778,\n",
       "         0.4178]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(10,10)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52284094-4750-4938-95ec-6c89a9dca31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad68ba1c-a565-44a7-bcfa-06f74708a724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7d30eda-12e1-46bf-8146-e6effd8959bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4865, 0.9664, 0.4096, 0.0645],\n",
       "         [0.6688, 0.6953, 0.3814, 0.0608],\n",
       "         [0.7103, 0.3705, 0.4934, 0.3434],\n",
       "         [0.7046, 0.8281, 0.0849, 0.5968]],\n",
       "\n",
       "        [[0.0286, 0.5839, 0.5521, 0.2899],\n",
       "         [0.5681, 0.0700, 0.9714, 0.8062],\n",
       "         [0.9553, 0.3507, 0.1937, 0.8033],\n",
       "         [0.0569, 0.9349, 0.0787, 0.2481]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(2, 4, 4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59a1e3bd-4d82-4e3e-b42c-de94c1f2310f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec7bb18b-8467-4349-afba-ea05ecd9e199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78fc81e7-c789-431f-91f3-5c11f6f5d956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(3,224,224)) # colour channels (R, G, B), height, width\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f7139c0-ffe3-4588-b9a8-756e2e430049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6714, 0.7346, 0.2128,  ..., 0.7190, 0.5567, 0.6936],\n",
      "         [0.7993, 0.8540, 0.5141,  ..., 0.9399, 0.8708, 0.5798],\n",
      "         [0.3986, 0.1336, 0.8669,  ..., 0.6050, 0.4430, 0.0519],\n",
      "         ...,\n",
      "         [0.2993, 0.1297, 0.3535,  ..., 0.0121, 0.8110, 0.1019],\n",
      "         [0.1161, 0.1573, 0.7322,  ..., 0.5176, 0.5216, 0.4523],\n",
      "         [0.3676, 0.8418, 0.4333,  ..., 0.9991, 0.4455, 0.5922]],\n",
      "\n",
      "        [[0.1643, 0.8817, 0.6002,  ..., 0.5215, 0.8205, 0.9717],\n",
      "         [0.6893, 0.3937, 0.5095,  ..., 0.2777, 0.2613, 0.1660],\n",
      "         [0.1069, 0.4520, 0.2465,  ..., 0.3674, 0.7447, 0.2222],\n",
      "         ...,\n",
      "         [0.8363, 0.0531, 0.6384,  ..., 0.7093, 0.9391, 0.4417],\n",
      "         [0.6617, 0.9378, 0.5295,  ..., 0.3034, 0.0568, 0.0605],\n",
      "         [0.0995, 0.2474, 0.6538,  ..., 0.4881, 0.1360, 0.4678]],\n",
      "\n",
      "        [[0.5547, 0.7117, 0.8755,  ..., 0.4048, 0.8643, 0.3159],\n",
      "         [0.6522, 0.9339, 0.7293,  ..., 0.4907, 0.5416, 0.8191],\n",
      "         [0.0733, 0.6433, 0.6744,  ..., 0.0203, 0.9849, 0.9890],\n",
      "         ...,\n",
      "         [0.3113, 0.2072, 0.6332,  ..., 0.6797, 0.9120, 0.6160],\n",
      "         [0.0477, 0.9569, 0.0996,  ..., 0.3182, 0.7910, 0.8691],\n",
      "         [0.4115, 0.9040, 0.8637,  ..., 0.1134, 0.7202, 0.3331]]])\n"
     ]
    }
   ],
   "source": [
    "print(random_image_size_tensor) # Do not need this print statement in Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8a9df4-c173-4d51-aee0-d194585663e4",
   "metadata": {},
   "source": [
    "    Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e670c7d9-1ef5-4c7e-b478-1910c7655820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa08c876-7244-486a-be09-da3b7c3862a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(3,4) # To reset my playing around with code above\n",
    "zeros * random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a4411e3-69aa-4c8c-9e6e-18804a673d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3,4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29754011-51a5-4192-9db6-1ad41904e4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b92137d-b994-4372-af82-9f9adeec2e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd379f66-4f99-452e-ae41-5ef7af663bcd",
   "metadata": {},
   "source": [
    "    Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a224826d-59c4-4920-b59e-d5a5ee4e2e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.arange()\n",
    "torch.arange(0,10)\n",
    "\n",
    "# torch.range() no longer works with my version of PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68cb9670-f677-42c8-b616-54c2099fac4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  77, 154, 231, 308, 385, 462, 539, 616, 693, 770, 847, 924])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "something = torch.arange(start=0, end=1000, step=77)\n",
    "something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36fd478b-6b11-44a1-8e30-51667876591e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "something.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6ad93cd-b5b9-42ee-9d75-423b8f7255fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "something.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "858621c3-b250-47af-a72d-dc64a2fc06fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a tensors like\n",
    "ten_zeros = torch.zeros_like(input=something)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a1260-6b02-4ac4-8754-cb86a6f4d49e",
   "metadata": {},
   "source": [
    "    Tensor datatypes\n",
    "\n",
    "        Tensor datatypes is one the 3 big errors you'll run into with PyTorch and deep learning\n",
    "            - Tensors not right datatype\n",
    "            - Tensors not right shape\n",
    "            - Tensors not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2aae0525-1e5d-40d2-a187-c2725c4cec9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], \n",
    "                               dtype=None, # what datatype is the tensor (e.g. float32 or float16)\n",
    "                               device=None, # what device is you tensor on\n",
    "                                   # defualt is \"cpu\"\n",
    "                                   # can change it to \"cuda\"\n",
    "                               requires_grad=False) # whether or not to track gradients with this tensor operations\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "97c070e0-659b-4c73-8a80-c57b35cc2572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f25cdb66-9f5c-445f-8b23-70a9930ff306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.half)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9e869216-1e24-4a4d-803b-92aa52621d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor = float_16_tensor * float_32_tensor\n",
    "test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "43790a51-8076-44fb-a5f6-34f6e751095b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "211bdec3-b530-4af9-853c-1247cebde5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3,6,9], dtype=torch.int32)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a106a151-086b-4711-a1e9-458b2eee4689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor = float_32_tensor * int_32_tensor\n",
    "test_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d290bca-3bc4-4ac4-ba79-091c063d9316",
   "metadata": {},
   "source": [
    "    Getting information from tensors (Tensor attributes)\n",
    "\n",
    "        To get datatype from a tensor, use 'tensor.dtype'\n",
    "        To get shape from a tensor, use 'tensor.shape'\n",
    "        To get device from a tensor, use 'tensor.device'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f40a1a12-4a45-4a0a-8182-1fd8c9b2f74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4857, 0.4724, 0.4198, 0.9446],\n",
       "        [0.3382, 0.0089, 0.2065, 0.7708],\n",
       "        [0.0024, 0.4076, 0.5298, 0.0108]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9cf3f421-8e6d-4b7d-8773-4b1132e42a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4857, 0.4724, 0.4198, 0.9446],\n",
      "        [0.3382, 0.0089, 0.2065, 0.7708],\n",
      "        [0.0024, 0.4076, 0.5298, 0.0108]])\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device tensor is on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Find out details about some tensor\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device tensor is on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f45db9a9-09c8-4554-a44b-525f0860f598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]), torch.Size([3, 4]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.size(), some_tensor.shape  # not some_tensor.size... it is not an attribute, but a function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e77c8b-e417-4853-8168-b2cd172e37df",
   "metadata": {},
   "source": [
    "    Manipulating Tensors (Tensor operations)\n",
    "\n",
    "        Tensor operations include:\n",
    "            - addition\n",
    "            - subtractions\n",
    "            - multiplication (element-wise)\n",
    "            - division\n",
    "            - matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e6fc92f4-0b39-4cca-ae8b-543be239d05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1025, 1026, 1027])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "25607e70-8d14-4517-8b71-41adc1cd1efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0b4f04ce-edb6-4088-a743-1b33e9447ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "75619871-2605-4feb-a965-c93a131cad8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100, 200, 300])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor * 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4848bde1-af8b-482c-9769-1b60b788f3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "494724cb-afec-4894-98a5-27eea2983636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e641684e-d361-42da-9c33-e9f54dc0aef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(tensor,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "50d5848f-c94f-40a8-8428-a56b70d31696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9fc4eafa-f33a-4d14-bfda-7a77b351edd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "889d0951-d6dc-458a-8f36-4c8ac97be950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sub(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6412f6fc-def7-49a1-b8af-a9ff84ad1e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 1.0000, 1.5000])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.div(tensor, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a387ad-8945-4a7b-86cf-aff49c3425cf",
   "metadata": {},
   "source": [
    "    Matrix Multiplication\n",
    "\n",
    "        Two main ways of performing multiplication in neural netwroks and deep learning:\n",
    "            - element-wise multiplication\n",
    "            - matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fa91c54e-f29b-4d17-9f4d-2b025684b5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication\n",
    "print(tensor, \"*\", tensor)\n",
    "print(f\"Equals: {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7308f71a-88c6-4390-b61f-9dfbcca3721f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix Multiplication\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "922a7368-52a5-4cf3-bfc6-42653de3b469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication by hand\n",
    "1*1 + 2*2 + 3*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d225f094-17be-4c41-ba20-211a2bcf1ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b488fdb2-a550-4f74-8f3c-7d041d51b109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63da835c-1374-4e3d-bd21-1e6944bdc752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
